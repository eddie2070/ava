{"ast":null,"code":"'use strict';\n\nvar Readable = require('readable-stream');\n\nvar util = require('util'); // some versions of the buffer browser lib don't support Buffer.from (such as the one included by the current version of express-browserify)\n\n\nvar bufferFrom = require('buffer-from');\n/**\n * Turns a MediaStream object (from getUserMedia) into a Node.js Readable stream and optionally converts the audio to Buffers\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia\n *\n * @param {Object} [opts] options\n * @param {MediaStream} [opts.stream] https://developer.mozilla.org/en-US/docs/Web/API/MediaStream - for iOS compatibility, it is recommended that you create the MicrophoneStream instance in response to the tap - before you have a MediaStream, and then later call setStream() with the MediaStream.\n * @param {Boolean} [opts.objectMode=false] Puts the stream into ObjectMode where it emits AudioBuffers instead of Buffers - see https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer\n * @param {Number|null} [opts.bufferSize=null] https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n * @param {AudioContext} [opts.context] - AudioContext - will be automatically created if not passed in\n * @constructor\n */\n\n\nfunction MicrophoneStream(opts) {\n  // backwards compatibility - passing in the Stream here will generally not work on iOS 11 Safari\n  if (typeof MediaStream !== 'undefined' && opts instanceof MediaStream) {\n    var stream = opts;\n    opts = arguments[1] || {};\n    opts.stream = stream;\n  }\n\n  opts = opts || {}; // \"It is recommended for authors to not specify this buffer size and allow the implementation to pick a good\n  // buffer size to balance between latency and audio quality.\"\n  // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n  // however, webkitAudioContext (safari) requires it to be set'\n  // Possible values: null, 256, 512, 1024, 2048, 4096, 8192, 16384\n\n  var bufferSize = typeof window.AudioContext === 'undefined' ? 4096 : null;\n  bufferSize = opts.bufferSize || bufferSize; // We can only emit one channel's worth of audio, so only one input. (Who has multiple microphones anyways?)\n\n  var inputChannels = 1; // we shouldn't need any output channels (going back to the browser), but chrome is buggy and won't give us any audio without one\n\n  var outputChannels = 1;\n  Readable.call(this, opts);\n  var self = this;\n  var recording = true;\n  /**\n   * Convert and emit the raw audio data\n   * @see https://developer.mozilla.org/en-US/docs/Web/API/ScriptProcessorNode/onaudioprocess\n   * @param {AudioProcessingEvent} e https://developer.mozilla.org/en-US/docs/Web/API/AudioProcessingEvent\n   */\n\n  function recorderProcess(e) {\n    // onaudioprocess can be called at least once after we've stopped\n    if (recording) {\n      self.push(opts.objectMode ? e.inputBuffer : bufferFrom(e.inputBuffer.getChannelData(0).buffer));\n    }\n  }\n\n  var AudioContext = window.AudioContext || window.webkitAudioContext;\n  var context = this.context = opts.context || new AudioContext();\n  var recorder = context.createScriptProcessor(bufferSize, inputChannels, outputChannels); // other half of workaround for chrome bugs\n\n  recorder.connect(context.destination);\n  var audioInput;\n  /**\n   * Set the MediaStream\n   *\n   * This was separated from the constructor to enable better compatibility with Safari on iOS 11.\n   *\n   * Typically the stream is only available asynchronously, but the context must be created or resumed directly in\n   * response to a user's tap on iOS.\n   *\n   * @param {MediaStream} stream https://developer.mozilla.org/en-US/docs/Web/API/MediaStream\n   */\n\n  this.setStream = function (stream) {\n    this.stream = stream;\n    audioInput = context.createMediaStreamSource(stream);\n    audioInput.connect(recorder);\n    recorder.onaudioprocess = recorderProcess;\n  };\n\n  if (opts.stream) {\n    this.setStream(stream);\n  }\n\n  this.stop = function () {\n    if (context.state === 'closed') {\n      return;\n    }\n\n    try {\n      this.stream.getTracks()[0].stop();\n    } catch (ex) {// This fails in some older versions of chrome. Nothing we can do about it.\n    }\n\n    recorder.disconnect();\n\n    if (audioInput) {\n      audioInput.disconnect();\n    }\n\n    try {\n      context.close(); // returns a promise;\n    } catch (ex) {// this can also fail in older versions of chrome\n    }\n\n    recording = false;\n    self.push(null);\n    self.emit('close');\n  };\n\n  process.nextTick(function () {\n    self.emit('format', {\n      channels: 1,\n      bitDepth: 32,\n      sampleRate: context.sampleRate,\n      signed: true,\n      float: true\n    });\n  });\n}\n\nutil.inherits(MicrophoneStream, Readable);\n\nMicrophoneStream.prototype._read = function ()\n/* bytes */\n{// no-op, (flow-control doesn't really work on live audio)\n};\n/**\n * Converts a Buffer back into the raw Float32Array format that browsers use.\n * Note: this is just a new DataView for the same underlying buffer -\n * the actual audio data is not copied or changed here.\n *\n * @param {Buffer} chunk node-style buffer of audio data from a 'data' event or read() call\n * @return {Float32Array} raw 32-bit float data view of audio data\n */\n\n\nMicrophoneStream.toRaw = function toFloat32(chunk) {\n  return new Float32Array(chunk.buffer);\n};\n\nmodule.exports = MicrophoneStream;","map":{"version":3,"sources":["/home/ec2-user/environment/myapp/node_modules/microphone-stream/microphone-stream.js"],"names":["Readable","require","util","bufferFrom","MicrophoneStream","opts","MediaStream","stream","arguments","bufferSize","window","AudioContext","inputChannels","outputChannels","call","self","recording","recorderProcess","e","push","objectMode","inputBuffer","getChannelData","buffer","webkitAudioContext","context","recorder","createScriptProcessor","connect","destination","audioInput","setStream","createMediaStreamSource","onaudioprocess","stop","state","getTracks","ex","disconnect","close","emit","process","nextTick","channels","bitDepth","sampleRate","signed","float","inherits","prototype","_read","toRaw","toFloat32","chunk","Float32Array","module","exports"],"mappings":"AAAA;;AACA,IAAIA,QAAQ,GAAGC,OAAO,CAAC,iBAAD,CAAtB;;AACA,IAAIC,IAAI,GAAGD,OAAO,CAAC,MAAD,CAAlB,C,CACA;;;AACA,IAAIE,UAAU,GAAGF,OAAO,CAAC,aAAD,CAAxB;AAEA;;;;;;;;;;;;;;AAYA,SAASG,gBAAT,CAA0BC,IAA1B,EAAgC;AAC9B;AACA,MAAI,OAAOC,WAAP,KAAuB,WAAvB,IAAsCD,IAAI,YAAYC,WAA1D,EAAuE;AACrE,QAAIC,MAAM,GAAGF,IAAb;AACAA,IAAAA,IAAI,GAAGG,SAAS,CAAC,CAAD,CAAT,IAAgB,EAAvB;AACAH,IAAAA,IAAI,CAACE,MAAL,GAAcA,MAAd;AACD;;AAEDF,EAAAA,IAAI,GAAGA,IAAI,IAAI,EAAf,CAR8B,CAU9B;AACA;AACA;AACA;AACA;;AACA,MAAII,UAAU,GAAI,OAAOC,MAAM,CAACC,YAAd,KAA+B,WAA/B,GAA6C,IAA7C,GAAoD,IAAtE;AACAF,EAAAA,UAAU,GAAGJ,IAAI,CAACI,UAAL,IAAmBA,UAAhC,CAhB8B,CAkB9B;;AACA,MAAIG,aAAa,GAAG,CAApB,CAnB8B,CAqB9B;;AACA,MAAIC,cAAc,GAAG,CAArB;AAEAb,EAAAA,QAAQ,CAACc,IAAT,CAAc,IAAd,EAAoBT,IAApB;AAEA,MAAIU,IAAI,GAAG,IAAX;AACA,MAAIC,SAAS,GAAG,IAAhB;AAEA;;;;;;AAKA,WAASC,eAAT,CAAyBC,CAAzB,EAA4B;AAC1B;AACA,QAAIF,SAAJ,EAAe;AACbD,MAAAA,IAAI,CAACI,IAAL,CAAUd,IAAI,CAACe,UAAL,GAAkBF,CAAC,CAACG,WAApB,GAAkClB,UAAU,CAACe,CAAC,CAACG,WAAF,CAAcC,cAAd,CAA6B,CAA7B,EAAgCC,MAAjC,CAAtD;AACD;AACF;;AAED,MAAIZ,YAAY,GAAGD,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACc,kBAAjD;AACA,MAAIC,OAAO,GAAG,KAAKA,OAAL,GAAepB,IAAI,CAACoB,OAAL,IAAgB,IAAId,YAAJ,EAA7C;AACA,MAAIe,QAAQ,GAAGD,OAAO,CAACE,qBAAR,CAA8BlB,UAA9B,EAA0CG,aAA1C,EAAyDC,cAAzD,CAAf,CA3C8B,CA6C9B;;AACAa,EAAAA,QAAQ,CAACE,OAAT,CAAiBH,OAAO,CAACI,WAAzB;AAEA,MAAIC,UAAJ;AAEA;;;;;;;;;;;AAUA,OAAKC,SAAL,GAAiB,UAASxB,MAAT,EAAiB;AAChC,SAAKA,MAAL,GAAcA,MAAd;AACAuB,IAAAA,UAAU,GAAGL,OAAO,CAACO,uBAAR,CAAgCzB,MAAhC,CAAb;AACAuB,IAAAA,UAAU,CAACF,OAAX,CAAmBF,QAAnB;AACAA,IAAAA,QAAQ,CAACO,cAAT,GAA0BhB,eAA1B;AACD,GALD;;AAOA,MAAIZ,IAAI,CAACE,MAAT,EAAiB;AACf,SAAKwB,SAAL,CAAexB,MAAf;AACD;;AAGD,OAAK2B,IAAL,GAAY,YAAW;AACrB,QAAIT,OAAO,CAACU,KAAR,KAAkB,QAAtB,EAAgC;AAC9B;AACD;;AACD,QAAI;AACF,WAAK5B,MAAL,CAAY6B,SAAZ,GAAwB,CAAxB,EAA2BF,IAA3B;AACD,KAFD,CAEE,OAAOG,EAAP,EAAW,CACX;AACD;;AACDX,IAAAA,QAAQ,CAACY,UAAT;;AACA,QAAIR,UAAJ,EAAgB;AACdA,MAAAA,UAAU,CAACQ,UAAX;AACD;;AACD,QAAI;AACFb,MAAAA,OAAO,CAACc,KAAR,GADE,CACe;AAClB,KAFD,CAEE,OAAOF,EAAP,EAAW,CACX;AACD;;AACDrB,IAAAA,SAAS,GAAG,KAAZ;AACAD,IAAAA,IAAI,CAACI,IAAL,CAAU,IAAV;AACAJ,IAAAA,IAAI,CAACyB,IAAL,CAAU,OAAV;AACD,GArBD;;AAuBAC,EAAAA,OAAO,CAACC,QAAR,CAAiB,YAAW;AAC1B3B,IAAAA,IAAI,CAACyB,IAAL,CAAU,QAAV,EAAoB;AAClBG,MAAAA,QAAQ,EAAE,CADQ;AAElBC,MAAAA,QAAQ,EAAE,EAFQ;AAGlBC,MAAAA,UAAU,EAAEpB,OAAO,CAACoB,UAHF;AAIlBC,MAAAA,MAAM,EAAE,IAJU;AAKlBC,MAAAA,KAAK,EAAE;AALW,KAApB;AAOD,GARD;AASD;;AACD7C,IAAI,CAAC8C,QAAL,CAAc5C,gBAAd,EAAgCJ,QAAhC;;AAEAI,gBAAgB,CAAC6C,SAAjB,CAA2BC,KAA3B,GAAmC;AAAS;AAAa,CACvD;AACD,CAFD;AAIA;;;;;;;;;;AAQA9C,gBAAgB,CAAC+C,KAAjB,GAAyB,SAASC,SAAT,CAAmBC,KAAnB,EAA0B;AACjD,SAAO,IAAIC,YAAJ,CAAiBD,KAAK,CAAC9B,MAAvB,CAAP;AACD,CAFD;;AAIAgC,MAAM,CAACC,OAAP,GAAiBpD,gBAAjB","sourcesContent":["'use strict';\nvar Readable = require('readable-stream');\nvar util = require('util');\n// some versions of the buffer browser lib don't support Buffer.from (such as the one included by the current version of express-browserify)\nvar bufferFrom = require('buffer-from');\n\n/**\n * Turns a MediaStream object (from getUserMedia) into a Node.js Readable stream and optionally converts the audio to Buffers\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia\n *\n * @param {Object} [opts] options\n * @param {MediaStream} [opts.stream] https://developer.mozilla.org/en-US/docs/Web/API/MediaStream - for iOS compatibility, it is recommended that you create the MicrophoneStream instance in response to the tap - before you have a MediaStream, and then later call setStream() with the MediaStream.\n * @param {Boolean} [opts.objectMode=false] Puts the stream into ObjectMode where it emits AudioBuffers instead of Buffers - see https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer\n * @param {Number|null} [opts.bufferSize=null] https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n * @param {AudioContext} [opts.context] - AudioContext - will be automatically created if not passed in\n * @constructor\n */\nfunction MicrophoneStream(opts) {\n  // backwards compatibility - passing in the Stream here will generally not work on iOS 11 Safari\n  if (typeof MediaStream !== 'undefined' && opts instanceof MediaStream) {\n    var stream = opts;\n    opts = arguments[1] || {};\n    opts.stream = stream;\n  }\n\n  opts = opts || {};\n\n  // \"It is recommended for authors to not specify this buffer size and allow the implementation to pick a good\n  // buffer size to balance between latency and audio quality.\"\n  // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor\n  // however, webkitAudioContext (safari) requires it to be set'\n  // Possible values: null, 256, 512, 1024, 2048, 4096, 8192, 16384\n  var bufferSize = (typeof window.AudioContext === 'undefined' ? 4096 : null);\n  bufferSize = opts.bufferSize || bufferSize;\n\n  // We can only emit one channel's worth of audio, so only one input. (Who has multiple microphones anyways?)\n  var inputChannels = 1;\n\n  // we shouldn't need any output channels (going back to the browser), but chrome is buggy and won't give us any audio without one\n  var outputChannels = 1;\n\n  Readable.call(this, opts);\n\n  var self = this;\n  var recording = true;\n\n  /**\n   * Convert and emit the raw audio data\n   * @see https://developer.mozilla.org/en-US/docs/Web/API/ScriptProcessorNode/onaudioprocess\n   * @param {AudioProcessingEvent} e https://developer.mozilla.org/en-US/docs/Web/API/AudioProcessingEvent\n   */\n  function recorderProcess(e) {\n    // onaudioprocess can be called at least once after we've stopped\n    if (recording) {\n      self.push(opts.objectMode ? e.inputBuffer : bufferFrom(e.inputBuffer.getChannelData(0).buffer));\n    }\n  }\n\n  var AudioContext = window.AudioContext || window.webkitAudioContext;\n  var context = this.context = opts.context || new AudioContext();\n  var recorder = context.createScriptProcessor(bufferSize, inputChannels, outputChannels);\n\n  // other half of workaround for chrome bugs\n  recorder.connect(context.destination);\n\n  var audioInput;\n\n  /**\n   * Set the MediaStream\n   *\n   * This was separated from the constructor to enable better compatibility with Safari on iOS 11.\n   *\n   * Typically the stream is only available asynchronously, but the context must be created or resumed directly in\n   * response to a user's tap on iOS.\n   *\n   * @param {MediaStream} stream https://developer.mozilla.org/en-US/docs/Web/API/MediaStream\n   */\n  this.setStream = function(stream) {\n    this.stream = stream;\n    audioInput = context.createMediaStreamSource(stream);\n    audioInput.connect(recorder);\n    recorder.onaudioprocess = recorderProcess;\n  };\n\n  if (opts.stream) {\n    this.setStream(stream);\n  }\n\n\n  this.stop = function() {\n    if (context.state === 'closed') {\n      return;\n    }\n    try {\n      this.stream.getTracks()[0].stop();\n    } catch (ex) {\n      // This fails in some older versions of chrome. Nothing we can do about it.\n    }\n    recorder.disconnect();\n    if (audioInput) {\n      audioInput.disconnect();\n    }\n    try {\n      context.close(); // returns a promise;\n    } catch (ex) {\n      // this can also fail in older versions of chrome\n    }\n    recording = false;\n    self.push(null);\n    self.emit('close');\n  };\n\n  process.nextTick(function() {\n    self.emit('format', {\n      channels: 1,\n      bitDepth: 32,\n      sampleRate: context.sampleRate,\n      signed: true,\n      float: true\n    });\n  });\n}\nutil.inherits(MicrophoneStream, Readable);\n\nMicrophoneStream.prototype._read = function(/* bytes */) {\n  // no-op, (flow-control doesn't really work on live audio)\n};\n\n/**\n * Converts a Buffer back into the raw Float32Array format that browsers use.\n * Note: this is just a new DataView for the same underlying buffer -\n * the actual audio data is not copied or changed here.\n *\n * @param {Buffer} chunk node-style buffer of audio data from a 'data' event or read() call\n * @return {Float32Array} raw 32-bit float data view of audio data\n */\nMicrophoneStream.toRaw = function toFloat32(chunk) {\n  return new Float32Array(chunk.buffer);\n};\n\nmodule.exports = MicrophoneStream;\n"]},"metadata":{},"sourceType":"script"}